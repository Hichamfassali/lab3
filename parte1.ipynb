{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10092079,"sourceType":"datasetVersion","datasetId":6223229}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport pandas as pd\nimport regex as re\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:56:13.369333Z","iopub.execute_input":"2024-12-03T20:56:13.370140Z","iopub.status.idle":"2024-12-03T20:56:13.377391Z","shell.execute_reply.started":"2024-12-03T20:56:13.370106Z","shell.execute_reply":"2024-12-03T20:56:13.376523Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import scrapy\nfrom scrapy.crawler import CrawlerProcess\nimport json\n\nclass HealthSpider(scrapy.Spider):\n    name = 'health'\n    start_urls = ['https://www.webteb.com/diseases']\n\n    def parse(self, response):\n        items = response.css('div.content.acc-content ul.list li')\n        for item in items:\n            disease_type = item.css('a::text').get().strip()\n            disease_link = item.css('a::attr(href)').get()\n            base_link = disease_link.split('/diseases')[0]\n            full_link = response.urljoin(base_link + \"/diseases/\")\n            yield scrapy.Request(url=full_link, callback=self.parse_disease_list, meta={'disease_type': disease_type, 'link': full_link})\n\n    def parse_disease_list(self, response):\n        disease_type = response.meta['disease_type']\n        diseases = response.css('div.search-result.border div.content')\n        for disease in diseases:\n            disease_name = disease.css('a.bold span::text').get().strip()\n            disease_link = disease.css('a.bold::attr(href)').get()\n            full_disease_link = response.urljoin(disease_link)\n            yield scrapy.Request(url=full_disease_link, callback=self.parse_disease_details, meta={'disease_type': disease_type, 'disease_name': disease_name})\n\n    def parse_disease_details(self, response):\n        disease_type = response.meta['disease_type']\n        disease_name = response.meta['disease_name']\n        \n        # Extracting data for each section\n        description = response.css('div#description').xpath('string()').get().strip()\n        symptoms_title = response.css('div#symptoms > h2::text').get()\n        symptoms = '\\n'.join(response.css('div#symptoms ul li::text').getall())\n        causes_and_risk_factors_title = response.css('div#causesandriskfactors > h2::text').get()\n        causes_and_risk_factors = '\\n'.join(response.css('div#causesandriskfactors ul li::text').getall())\n        complications_title = response.css('div#complications > h2::text').get()\n        complications = '\\n'.join(response.css('div#complications ul li::text').getall())\n        diagnosis_title = response.css('div#diagnosis > h2::text').get()\n        diagnosis = '\\n'.join(response.css('div#diagnosis ul li::text').getall())\n        treatments_and_drugs_title = response.css('div#treatementsanddrugs > h2::text').get()\n        treatments_and_drugs = '\\n'.join(response.css('div#treatementsanddrugs p::text').getall())\n        prevention_title = response.css('div#prevention > h2::text').get()\n        prevention = '\\n'.join(response.css('div#prevention ul li::text').getall())\n\n        content = f\"{disease_type}\\n{disease_name}\\n{description}\\n\\n{symptoms_title}:\\n{symptoms}\\n\\n{causes_and_risk_factors_title}:\\n{causes_and_risk_factors}\\n\\n{complications_title}:\\n{complications}\\n\\n{diagnosis_title}:\\n{diagnosis}\\n\\n{treatments_and_drugs_title}:\\n{treatments_and_drugs}\\n\\n{prevention_title}:\\n{prevention}\"\n\n        yield {\n            'disease_type': disease_type,\n            'disease_name': disease_name,\n            'content': content\n        }\n\n\n# Create a process to run the spider\nprocess = CrawlerProcess(settings={\n    'FEEDS': {\n        'disease_details2.json': {\n            'format': 'json',\n            'encoding': 'utf8',\n            'overwrite': True,\n        },\n    },\n})\n\n# Run the spider\nprocess.crawl(HealthSpider)\nprocess.start()\n\n# Load and display the data from the JSON file\nwith open('disease_details2.json', 'r', encoding='utf8') as f:\n    disease_details = json.load(f)\n\n# Display the extracted data\nfor item in disease_details:\n    print(item['content'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load your JSON data with utf-8 encoding\nwith open('/kaggle/input/disease/disease_details1.json', 'r', encoding='utf-8') as json_file:\n    data = json.load(json_file)\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Add an empty column named \"score\"\ndf = df.assign(score='')\n\n# Display the first few rows\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:28:55.169061Z","iopub.execute_input":"2024-12-03T20:28:55.169412Z","iopub.status.idle":"2024-12-03T20:28:55.220173Z","shell.execute_reply.started":"2024-12-03T20:28:55.169380Z","shell.execute_reply":"2024-12-03T20:28:55.219331Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   disease_type                 disease_name  \\\n0  تسوس الأسنان  امراض الاغشية المخاطية للفم   \n1  تسوس الأسنان            امراض التهاب اللب   \n2  تسوس الأسنان         عيوب خلقية لجوف الفم   \n3    مرض السكري             حساسية الإنسولين   \n4  تسوس الأسنان               ساركوما كابوزي   \n\n                                             content score  \n0  تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...        \n1  تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...        \n2  تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...        \n3  مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...        \n4  تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...        ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>disease_type</th>\n      <th>disease_name</th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض الاغشية المخاطية للفم</td>\n      <td>تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض التهاب اللب</td>\n      <td>تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تسوس الأسنان</td>\n      <td>عيوب خلقية لجوف الفم</td>\n      <td>تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>مرض السكري</td>\n      <td>حساسية الإنسولين</td>\n      <td>مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تسوس الأسنان</td>\n      <td>ساركوما كابوزي</td>\n      <td>تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Define the score_text function\ndef score_text(text):\n    # Define your scoring rules here\n    score = 0\n    \n    # Keywords related to symptoms\n    symptoms_keywords = ['ألم', 'عرض', 'علامة', 'ظهور', 'تشعر', 'تشعرين', 'يشعر', 'يعاني', 'يعانون', 'يعاني من', 'يعانون من', 'أعراض جانبية', 'تأثيرات جانبية', 'تغييرات في الجسم', 'وظائف غير طبيعية', 'مشاكل صحية', 'انزعاج', 'إزعاج', 'وجه', 'رأس', 'رقبة', 'صدر', 'ظهر', 'بطن', 'ذراع', 'ساق', 'مفصل', 'عضلة', 'جلد', 'شعر', 'أظافر', 'فم', 'لسان', 'أسنان', 'لثة', 'عيون', 'أذنين', 'أنف', 'شديد', 'حاد', 'خفيف', 'متوسط', 'مستمر', 'متقطع', 'مزمن', 'لا يطاق', 'غير محتمل', 'مُنهِك', 'مُؤلم', 'يُعيق', 'يُضعف', 'يُسبب إعاقة', 'حرقة', 'وخز', 'خدر', 'حكة', 'ألم غامض', 'ضعف', 'تشنج', 'غثيان', 'إقياء', 'إسهال', 'إمساك', 'سعال', 'ضيق تنفس', 'صعوبة في البلع', 'دوار', 'إغماء', 'نزيف', 'طفح جلدي', 'احمرار', 'تورم', 'جفاف', 'تقشر', 'تشقق', 'حكة', 'ألم عند اللمس', 'حساسية للمس', 'حساسية للحرارة', 'حساسية للبرودة', 'حساسية للضوء', 'حساسية للصوت', 'فقدان حاسة التذوق', 'فقدان حاسة الشم', 'قلق', 'اكتئاب', 'صداع', 'إرهاق', 'عصبية', 'توتر', 'اضطراب', 'مشاكل في النوم', 'ارتباك', 'تهيج', 'عدوانية', 'هلوسة', 'أوهام', 'فقدان التركيز', 'صعوبة في التفكير', 'صعوبة في اتخاذ القرارات', 'تغييرات في المزاج', 'سلوكيات غير طبيعية', 'ارتفاع درجة الحرارة', 'قشعريرة', 'حمى', 'قشعريرة', 'إفرازات مهبلية غير طبيعية', 'آلام الحوض', 'نزيف بين الدورات', 'نزيف بعد انقطاع الطمث', 'صعوبة التبول', 'إلحاح بولي', 'سلس البول', 'دم في البول', 'إفرازات قطنية بيضاء من المهبل', 'حرقان عند التبول', 'فرط التبول', 'تبول ليلي', 'ضعف الانتصاب', 'قلة الشهية']\n    for keyword in symptoms_keywords:\n        if keyword in text:\n            score += 1\n  \n    # Keywords related to causes and risk factors\n    causes_and_risk_factors_keywords = ['سبب', 'مسبب', 'عامل', 'يسبب', 'يؤدي إلى', 'يزيد من خطر', 'يقلل من خطر', 'مرض', 'عدوى', 'فيروس', 'بكتيريا', 'فطر', 'طفيلي', 'ورم', 'سرطان', 'خلل', 'اضطراب', 'حالة', 'وراثي', 'تاريخ عائلي', 'غذاء', 'تمارين', 'سمنة', 'تدخين', 'كحول', 'مخدرات', 'إجهاد', 'قلة نوم', 'تلوث', 'مواد كيميائية', 'إشعاع', 'لدغة', 'حشرة', 'إصابة', 'حادث', 'كسر', 'جرح', 'عمر', 'عوامل نفسية', 'ضغط عصبي', 'عوامل اجتماعية اقتصادية', 'فقر', 'انعدام الأمن الغذائي', 'إدمان الكحول والمخدرات', 'التعرض للعنف', 'التعرض للسموم', 'عوامل وراثية', 'طفرات جينية', 'عيوب خلقية', 'خلل التوازن الهرموني', 'أمراض المناعة الذاتية', 'استعداد وراثي', 'استهلاك الأدوية', 'التاريخ الطبي الشخصي', 'أمراض سابقة', 'الحمل', 'الرضاعة الطبيعية', 'سن اليأس', 'الجنس', 'العرق', 'النشاط البدني', 'تعرض أشعة الشمس']\n    for keyword in causes_and_risk_factors_keywords:\n        if keyword in text:\n            score += 1\n    \n    # Keywords related to complications\n    complications_keywords = ['مضاعفات', 'مضاعفة', 'يعقد', 'يؤدي إلى', 'يزيد من خطر', 'إعاقة', 'ضعف', 'فقدان وظيفة', 'اكتئاب', 'قلق', 'ألم مزمن', 'انتشار', 'وفاة', 'يهدد الحياة', 'تلف دائم', 'فشل عضوي', 'غيبوبة', 'عجز دائم', 'تشوهات', 'ندبات', 'التهاب مزمن', 'اضطرابات نفسية', 'اعتمادية على العلاج', 'انتكاس المرض', 'موت الأنسجة', 'نقص المناعة', 'سرطان ثانوي']\n    for keyword in complications_keywords:\n        if keyword in text:\n            score += 1\n    \n    # Keywords related to diagnosis\n    diagnosis_keywords = ['تشخيص', 'تشخيصي', 'يحدد', 'يكشف عن', 'يقيّم', 'تاريخ طبي', 'أعراض', 'فحص جسدي', 'فحص سريري', 'تحليل', 'فحص', 'تصوير', 'أشعة سينية', 'أشعة مقطعية', 'تصوير بالرنين المغناطيسي', 'تحليل دم', 'تحليل بول', 'خزعة', 'تنظير داخلي', 'تخطيط كهربية القلب', 'تخطيط كهربية الدماغ', 'قياس ضغط الدم', 'قياس السكر', 'اختبارات وظائف الكلى', 'اختبارات وظائف الكبد', 'اختبارات الحساسية', 'اختبارات الحمض النووي', 'فحص الحمض النووي', 'فحص جيني']\n    for keyword in diagnosis_keywords:\n        if keyword in text:\n            score += 1\n    \n    # Keywords related to treatments and drugs\n    treatments_and_drugs_keywords = ['علاج', 'علاج طبي', 'دواء', 'جرعة', 'جراحة', 'إشعاع', 'علاج طبيعي', 'علاج إشعاعي', 'علاج كيماوي', 'علاج بالهرمونات', 'علاج بالضوء', 'علاج سلوكي معرفي', 'علاج بالوخز بالإبر', 'علاج بالاسترخاء', 'علاج بالفن', 'علاج بالحمية الغذائية', 'علاج بديل', 'علاج تكميلي', 'جراحة من الحد الأدنى', 'جراحة تنظيرية', 'علاج بالخلايا الجذعية', 'علاج بالجينات', 'العلاج المناعي', 'المضادات الحيوية', 'مضادات الفيروسات', 'مضادات الفطريات', 'مضادات الطفيليات', 'مسكنات الألم', 'خافضات الحرارة', 'مضادات الالتهاب', 'مضادات الا']\n    for keyword in treatments_and_drugs_keywords:\n        if keyword in text:\n            score += 1\n    \n    # Keywords related to prevention\n    prevention_keywords = ['الوقاية', 'التوقي', 'الوقاية من', 'التوقي من', 'تجنب', 'تقليل', 'تحسين', 'الحد من', 'الوقاية الأولية', 'التوعية', 'التثقيف', 'التوجيه', 'النصائح', 'التوجيهات', 'التدابير', 'التدابير الوقائية', 'الإجراءات الوقائية', 'تغيير نمط الحياة', 'النظام الغذائي الصحي', 'ممارسة الرياضة', 'تجنب التدخين', 'التقليل من تناول الكحول', 'التقليل من تناول المخدرات', 'النوم الجيد', 'التقليل من التوتر', 'تجنب التعرض للعوامل الملوثة', 'التقليل من التعرض للإشعاع', 'استخدام وسائل الوقاية', 'التطعيم', 'التطهير', 'التعقيم', 'تنظيف اليدين', 'تنظيف البيئة', 'التغذية السليمة', 'العناية بالصحة النفسية', 'التوجيهات الطبية', 'الفحوصات الدورية', 'الكشف المبكر']\n    for keyword in prevention_keywords:\n        if keyword in text:\n            score += 1\n    \n    return score\n\n# Apply the score_text function to the 'content' column and update the 'score' column\ndf['score'] = df['content'].apply(score_text)\n\n# Display the updated DataFrame\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:29:20.908269Z","iopub.execute_input":"2024-12-03T20:29:20.908619Z","iopub.status.idle":"2024-12-03T20:29:21.728373Z","shell.execute_reply.started":"2024-12-03T20:29:20.908586Z","shell.execute_reply":"2024-12-03T20:29:21.727510Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   disease_type                 disease_name  \\\n0  تسوس الأسنان  امراض الاغشية المخاطية للفم   \n1  تسوس الأسنان            امراض التهاب اللب   \n2  تسوس الأسنان         عيوب خلقية لجوف الفم   \n3    مرض السكري             حساسية الإنسولين   \n4  تسوس الأسنان               ساركوما كابوزي   \n\n                                             content  score  \n0  تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...     37  \n1  تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...     37  \n2  تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...     42  \n3  مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...     20  \n4  تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...     25  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>disease_type</th>\n      <th>disease_name</th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض الاغشية المخاطية للفم</td>\n      <td>تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض التهاب اللب</td>\n      <td>تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تسوس الأسنان</td>\n      <td>عيوب خلقية لجوف الفم</td>\n      <td>تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>مرض السكري</td>\n      <td>حساسية الإنسولين</td>\n      <td>مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تسوس الأسنان</td>\n      <td>ساركوما كابوزي</td>\n      <td>تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def normalize_score(df, column_name):\n    # Find the minimum and maximum scores\n    min_score = df[column_name].min()\n    max_score = df[column_name].max()\n    \n    # Normalize the scores between 0 and 10\n    df['score'] = (df[column_name] - min_score) * 10 / (max_score - min_score)\n    \n    return df\n\n# Example usage:\n# Assuming df is your DataFrame and 'score' is the column containing scores\n# Replace 'score' with the actual column name in your DataFrame\ndf = normalize_score(df, 'score')\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:39:47.017007Z","iopub.execute_input":"2024-12-03T20:39:47.017355Z","iopub.status.idle":"2024-12-03T20:39:47.030235Z","shell.execute_reply.started":"2024-12-03T20:39:47.017326Z","shell.execute_reply":"2024-12-03T20:39:47.029496Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"    disease_type                 disease_name  \\\n0   تسوس الأسنان  امراض الاغشية المخاطية للفم   \n1   تسوس الأسنان            امراض التهاب اللب   \n2   تسوس الأسنان         عيوب خلقية لجوف الفم   \n3     مرض السكري             حساسية الإنسولين   \n4   تسوس الأسنان               ساركوما كابوزي   \n5   تسوس الأسنان                    جفاف الفم   \n6    تساقط الشعر                  تساقط الشعر   \n7   تسوس الأسنان                   رائحة الفم   \n8  الحمل المنتبذ              الولادة المبكرة   \n9  الحمل المنتبذ                      الإجهاض   \n\n                                             content     score  \n0  تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...  5.384615  \n1  تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...  5.384615  \n2  تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...  6.153846  \n3  مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...  2.769231  \n4  تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...  3.538462  \n5  تسوس الأسنان\\nجفاف الفم\\nيُساعد اللعاب على منع...  5.538462  \n6  تساقط الشعر\\nتساقط الشعر\\nأي شخص يُلاحظ أن شعر...  3.692308  \n7  تسوس الأسنان\\nرائحة الفم\\nيعاني العديد من الأش...  3.384615  \n8  الحمل المنتبذ\\nالولادة المبكرة\\nيستمر الحمل ال...  4.461538  \n9  الحمل المنتبذ\\nالإجهاض\\nالإجهاض هو الفقد التلق...  7.076923  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>disease_type</th>\n      <th>disease_name</th>\n      <th>content</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض الاغشية المخاطية للفم</td>\n      <td>تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...</td>\n      <td>5.384615</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض التهاب اللب</td>\n      <td>تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...</td>\n      <td>5.384615</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تسوس الأسنان</td>\n      <td>عيوب خلقية لجوف الفم</td>\n      <td>تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...</td>\n      <td>6.153846</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>مرض السكري</td>\n      <td>حساسية الإنسولين</td>\n      <td>مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...</td>\n      <td>2.769231</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تسوس الأسنان</td>\n      <td>ساركوما كابوزي</td>\n      <td>تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...</td>\n      <td>3.538462</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>تسوس الأسنان</td>\n      <td>جفاف الفم</td>\n      <td>تسوس الأسنان\\nجفاف الفم\\nيُساعد اللعاب على منع...</td>\n      <td>5.538462</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>تساقط الشعر</td>\n      <td>تساقط الشعر</td>\n      <td>تساقط الشعر\\nتساقط الشعر\\nأي شخص يُلاحظ أن شعر...</td>\n      <td>3.692308</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>تسوس الأسنان</td>\n      <td>رائحة الفم</td>\n      <td>تسوس الأسنان\\nرائحة الفم\\nيعاني العديد من الأش...</td>\n      <td>3.384615</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>الحمل المنتبذ</td>\n      <td>الولادة المبكرة</td>\n      <td>الحمل المنتبذ\\nالولادة المبكرة\\nيستمر الحمل ال...</td>\n      <td>4.461538</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>الحمل المنتبذ</td>\n      <td>الإجهاض</td>\n      <td>الحمل المنتبذ\\nالإجهاض\\nالإجهاض هو الفقد التلق...</td>\n      <td>7.076923</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import re\nimport pandas as pd\n\n# Define the basic_cleaning function\ndef basic_cleaning(text):\n    text = str(text)  # Convert to string to handle non-string inputs\n    text = text.lower()  # Lowercasing\n    text = re.sub(r'{.*?}', '', text)   # Remove CSS code within curly braces\n    # Removing all except alphanumeric characters, spaces, and specified characters\n    text = re.sub(r'[^\\w\\s\\-\\+\\*/!()\\[\\]{}<>]', '', text)\n    # Remove HTML tags\n    text = re.sub(r'<[^>]+>', '', text)\n    # Remove CSS\n    text = re.sub(r'<style[^>]*>[\\s\\S]+?</style>', '', text)\n    # Remove '\\n' and replace with space\n    text = text.replace('\\n', ' ')\n    # Remove non-Arabic characters and non-Arabic numbers\n    text = re.sub(r'[^\\u0621-\\u064A0-9\\s\\-\\+\\*/!\\[\\]{}<>]', '', text)\n\n    # Remove extra whitespaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Fill any NaN values with an empty string\ndf.fillna('', inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:40:11.736297Z","iopub.execute_input":"2024-12-03T20:40:11.737116Z","iopub.status.idle":"2024-12-03T20:40:11.743278Z","shell.execute_reply.started":"2024-12-03T20:40:11.737082Z","shell.execute_reply":"2024-12-03T20:40:11.742262Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')\nimport nltk\nnltk.download('popular')  # This will download the most common resources including wordnet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:59:27.251601Z","iopub.execute_input":"2024-12-03T20:59:27.251979Z","iopub.status.idle":"2024-12-03T20:59:27.918470Z","shell.execute_reply.started":"2024-12-03T20:59:27.251945Z","shell.execute_reply":"2024-12-03T20:59:27.917670Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n[nltk_data] Downloading collection 'popular'\n[nltk_data]    | \n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package omw-1.4 is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet2021 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet31 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection popular\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"\ndef tokenize(text):\n    return word_tokenize(text)\n\ndef remove_stopwords(tokens):\n    stop_words = set(stopwords.words('arabic'))\n    return [word for word in tokens if word not in stop_words]\n\ndef stem_tokens(tokens):\n    stemmer = PorterStemmer()\n    return [stemmer.stem(word) for word in tokens]\n\ndef lemmatize_tokens(tokens):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in tokens]\n\ndef preprocess_text(df, text_column):\n    df['cleaned_text'] = df[text_column].apply(basic_cleaning)\n    df['tokens'] = df['cleaned_text'].apply(tokenize)\n    df['tokens'] = df['tokens'].apply(remove_stopwords)\n    df['stemmed_tokens'] = df['tokens'].apply(lambda x: ' '.join(stem_tokens(x)))\n    df['lemmatized_tokens'] = df['tokens'].apply(lambda x: ' '.join(lemmatize_tokens(x)))\n    return df\n\npreprocessed_df = preprocess_text(df, 'content')\npreprocessed_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:03:52.782931Z","iopub.execute_input":"2024-12-03T21:03:52.783292Z","iopub.status.idle":"2024-12-03T21:04:04.303880Z","shell.execute_reply.started":"2024-12-03T21:03:52.783258Z","shell.execute_reply":"2024-12-03T21:04:04.302951Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   disease_type                 disease_name  \\\n0  تسوس الأسنان  امراض الاغشية المخاطية للفم   \n1  تسوس الأسنان            امراض التهاب اللب   \n2  تسوس الأسنان         عيوب خلقية لجوف الفم   \n3    مرض السكري             حساسية الإنسولين   \n4  تسوس الأسنان               ساركوما كابوزي   \n\n                                             content     score  \\\n0  تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...  5.384615   \n1  تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...  5.384615   \n2  تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...  6.153846   \n3  مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...  2.769231   \n4  تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...  3.538462   \n\n                                        cleaned_text  \\\n0  تسوس الأسنان امراض الاغشية المخاطية للفم تغطي ...   \n1  تسوس الأسنان امراض التهاب اللب قد يكون الالتها...   \n2  تسوس الأسنان عيوب خلقية لجوف الفم يوجد للفم وظ...   \n3  مرض السكري حساسية الإنسولين حتى نهاية سنوات ال...   \n4  تسوس الأسنان ساركوما كابوزي ساركوما كابوزي عبا...   \n\n                                              tokens  \\\n0  [تسوس, الأسنان, امراض, الاغشية, المخاطية, للفم...   \n1  [تسوس, الأسنان, امراض, التهاب, اللب, يكون, الا...   \n2  [تسوس, الأسنان, عيوب, خلقية, لجوف, الفم, يوجد,...   \n3  [مرض, السكري, حساسية, الإنسولين, نهاية, سنوات,...   \n4  [تسوس, الأسنان, ساركوما, كابوزي, ساركوما, كابو...   \n\n                                      stemmed_tokens  \\\n0  تسوس الأسنان امراض الاغشية المخاطية للفم تغطي ...   \n1  تسوس الأسنان امراض التهاب اللب يكون الالتهاب ا...   \n2  تسوس الأسنان عيوب خلقية لجوف الفم يوجد للفم وظ...   \n3  مرض السكري حساسية الإنسولين نهاية سنوات الثمان...   \n4  تسوس الأسنان ساركوما كابوزي ساركوما كابوزي عبا...   \n\n                                   lemmatized_tokens  \n0  تسوس الأسنان امراض الاغشية المخاطية للفم تغطي ...  \n1  تسوس الأسنان امراض التهاب اللب يكون الالتهاب ا...  \n2  تسوس الأسنان عيوب خلقية لجوف الفم يوجد للفم وظ...  \n3  مرض السكري حساسية الإنسولين نهاية سنوات الثمان...  \n4  تسوس الأسنان ساركوما كابوزي ساركوما كابوزي عبا...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>disease_type</th>\n      <th>disease_name</th>\n      <th>content</th>\n      <th>score</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n      <th>stemmed_tokens</th>\n      <th>lemmatized_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض الاغشية المخاطية للفم</td>\n      <td>تسوس الأسنان\\nامراض الاغشية المخاطية للفم\\nتغط...</td>\n      <td>5.384615</td>\n      <td>تسوس الأسنان امراض الاغشية المخاطية للفم تغطي ...</td>\n      <td>[تسوس, الأسنان, امراض, الاغشية, المخاطية, للفم...</td>\n      <td>تسوس الأسنان امراض الاغشية المخاطية للفم تغطي ...</td>\n      <td>تسوس الأسنان امراض الاغشية المخاطية للفم تغطي ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>تسوس الأسنان</td>\n      <td>امراض التهاب اللب</td>\n      <td>تسوس الأسنان\\nامراض التهاب اللب\\nقد يكون الالت...</td>\n      <td>5.384615</td>\n      <td>تسوس الأسنان امراض التهاب اللب قد يكون الالتها...</td>\n      <td>[تسوس, الأسنان, امراض, التهاب, اللب, يكون, الا...</td>\n      <td>تسوس الأسنان امراض التهاب اللب يكون الالتهاب ا...</td>\n      <td>تسوس الأسنان امراض التهاب اللب يكون الالتهاب ا...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>تسوس الأسنان</td>\n      <td>عيوب خلقية لجوف الفم</td>\n      <td>تسوس الأسنان\\nعيوب خلقية لجوف الفم\\nيوجد للفم ...</td>\n      <td>6.153846</td>\n      <td>تسوس الأسنان عيوب خلقية لجوف الفم يوجد للفم وظ...</td>\n      <td>[تسوس, الأسنان, عيوب, خلقية, لجوف, الفم, يوجد,...</td>\n      <td>تسوس الأسنان عيوب خلقية لجوف الفم يوجد للفم وظ...</td>\n      <td>تسوس الأسنان عيوب خلقية لجوف الفم يوجد للفم وظ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>مرض السكري</td>\n      <td>حساسية الإنسولين</td>\n      <td>مرض السكري\\nحساسية الإنسولين\\nحتى نهاية سنوات ...</td>\n      <td>2.769231</td>\n      <td>مرض السكري حساسية الإنسولين حتى نهاية سنوات ال...</td>\n      <td>[مرض, السكري, حساسية, الإنسولين, نهاية, سنوات,...</td>\n      <td>مرض السكري حساسية الإنسولين نهاية سنوات الثمان...</td>\n      <td>مرض السكري حساسية الإنسولين نهاية سنوات الثمان...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>تسوس الأسنان</td>\n      <td>ساركوما كابوزي</td>\n      <td>تسوس الأسنان\\nساركوما كابوزي\\nساركوما كابوزي ع...</td>\n      <td>3.538462</td>\n      <td>تسوس الأسنان ساركوما كابوزي ساركوما كابوزي عبا...</td>\n      <td>[تسوس, الأسنان, ساركوما, كابوزي, ساركوما, كابو...</td>\n      <td>تسوس الأسنان ساركوما كابوزي ساركوما كابوزي عبا...</td>\n      <td>تسوس الأسنان ساركوما كابوزي ساركوما كابوزي عبا...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"#importing the libraries for encoding\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom gensim.models import Word2Vec\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:09:12.190617Z","iopub.execute_input":"2024-12-03T21:09:12.191027Z","iopub.status.idle":"2024-12-03T21:09:20.016557Z","shell.execute_reply.started":"2024-12-03T21:09:12.190982Z","shell.execute_reply":"2024-12-03T21:09:20.015914Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(preprocessed_df['lemmatized_tokens'][983])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:10:04.753628Z","iopub.execute_input":"2024-12-03T21:10:04.754004Z","iopub.status.idle":"2024-12-03T21:10:04.759320Z","shell.execute_reply.started":"2024-12-03T21:10:04.753975Z","shell.execute_reply":"2024-12-03T21:10:04.758355Z"}},"outputs":[{"name":"stdout","text":"العيون حول الحول حول العيون حالة يلتقي محورا الرؤية العينين نقطة واحدة وقد يظهر الحول النظر الأمام الجانبين وقد يكون حالة ثابتة مستديمة متغيرة أوقات مختلفة أشكال الحول يتم التمييز عادة شكلين أساسيين الحول 1 الحول التصاحبي وهي الحالة تكون زاوية الحول مدى انحراف العين ثابتة اتجاهات النظر 2 الحول اللا تصاحبي وهي الحالة تختلف زاوية الحول باختلاف اتجاه النظر الشكل ينتج شلل واحدة العضلات تتحكم بحركات العين اتجاه انحراف العين يحدد نوع وشكل الحول حالة القبل الحول الداخلي الحول الإنسي يكون انحراف العين الداخل باتجاه الأنف حالة الخزر الحول الخارجي الحول الوحشي يكون انحراف العين الخارج باتجاه الأذن حالة الحول الفوقاني الحول المتجانس الأعلى يكون انحراف العين الأعلى حالة الحول التحتاني الحول المتجانس الأسفل يكون انحراف العين الأسفل يظهر حول العيون المراحل العمرية رغم معظم حالات الحول تظهر مرحلة الطفولة فالحول الداخلي الأطفال يظهر الأشهر الأولى عمر الطفل الحول الإنسي التكيفي فينشأ سن سنتين وثلاث سنوات ناتج الإصابة بمد البصر الحول يظهر التقدم السن يسمى الحول المكتسب الحالات الحول تكون نتيجة ضعف الرؤية العينين كلتيهما أسباب وعوامل خطر حول ضعف الرؤية واحدة الشلل الدماغي متلازمة داون استسقاء الرأس مرض خلقي ينتج عنه تراكم السوائل الدماغ أورام الدماغ السكتة الدماغية مضاعفات حول تشخيص حول علاج حول طرق علاج الحول يمكن تشمل تركيب نظارات طبية بشكل عام لتعديل وإصلاح حالة مد البصر وفي الأحيان تكون حاجة عملية جراحية عضلات العينين إصلاح حول العيون بواسطة عملية جراحية يرتكز بالأساس طريقة علاجية حديثة تعتمد حقن البوتوكس الطريقة فعالة فقط حالات الحول البسيطة الوقاية حول\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nfrom tensorflow.keras.layers import SimpleRNN, Bidirectional, GRU, LSTM, Dense","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:10:23.674501Z","iopub.execute_input":"2024-12-03T21:10:23.675213Z","iopub.status.idle":"2024-12-03T21:10:34.456369Z","shell.execute_reply.started":"2024-12-03T21:10:23.675177Z","shell.execute_reply":"2024-12-03T21:10:34.455662Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\n# Assuming your DataFrame is named preprocessed_df\n# Tokenize the text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(preprocessed_df['lemmatized_tokens'])\nsequences = tokenizer.texts_to_sequences(preprocessed_df['lemmatized_tokens'])\n\n# Pad the sequences\nmax_sequence_length = max([len(seq) for seq in sequences])\nX = pad_sequences(sequences, maxlen=max_sequence_length)\n\n# Prepare the labels\ny = preprocessed_df['score'].values\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:15:43.854434Z","iopub.execute_input":"2024-12-03T21:15:43.854813Z","iopub.status.idle":"2024-12-03T21:15:44.777492Z","shell.execute_reply.started":"2024-12-03T21:15:43.854782Z","shell.execute_reply":"2024-12-03T21:15:44.776485Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n\ndef create_rnn_model(input_shape):\n    model = Sequential()\n    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=input_shape))\n    model.add(SimpleRNN(128))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\nrnn_model = create_rnn_model(X_train.shape[1])\nrnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:18:50.151270Z","iopub.execute_input":"2024-12-03T21:18:50.151875Z","iopub.status.idle":"2024-12-03T21:19:25.445401Z","shell.execute_reply.started":"2024-12-03T21:18:50.151842Z","shell.execute_reply":"2024-12-03T21:19:25.444598Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733260732.438045     752 service.cc:145] XLA service 0x7fd6f0005b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733260732.438107     752 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/29\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 3s/step - loss: 20.7331 - mae: 4.4050","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1733260733.496637     752 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - loss: 14.7561 - mae: 3.5225 - val_loss: 2.1022 - val_mae: 1.2143\nEpoch 2/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 2.0134 - mae: 1.1344 - val_loss: 1.5732 - val_mae: 0.9819\nEpoch 3/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 1.5805 - mae: 0.9762 - val_loss: 1.5621 - val_mae: 0.9843\nEpoch 4/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 1.5813 - mae: 0.9653 - val_loss: 1.5591 - val_mae: 0.9810\nEpoch 5/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 1.2898 - mae: 0.8643 - val_loss: 1.5714 - val_mae: 0.9730\nEpoch 6/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 1.1629 - mae: 0.8002 - val_loss: 1.5645 - val_mae: 0.9706\nEpoch 7/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.6967 - mae: 0.6061 - val_loss: 1.6205 - val_mae: 0.9712\nEpoch 8/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.3048 - mae: 0.3878 - val_loss: 1.7051 - val_mae: 0.9927\nEpoch 9/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.1315 - mae: 0.2428 - val_loss: 1.6755 - val_mae: 0.9949\nEpoch 10/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0846 - mae: 0.1933 - val_loss: 1.6529 - val_mae: 0.9963\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fd7558470a0>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"from tensorflow.keras.layers import Bidirectional\n\ndef create_bidirectional_rnn_model(input_shape):\n    model = Sequential()\n    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=input_shape))\n    model.add(Bidirectional(SimpleRNN(128)))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\nbidirectional_rnn_model = create_bidirectional_rnn_model(X_train.shape[1])\nbidirectional_rnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:21:37.370851Z","iopub.execute_input":"2024-12-03T21:21:37.371663Z","iopub.status.idle":"2024-12-03T21:22:40.936397Z","shell.execute_reply.started":"2024-12-03T21:21:37.371614Z","shell.execute_reply":"2024-12-03T21:22:40.935471Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 252ms/step - loss: 9.7206 - mae: 2.5788 - val_loss: 1.6641 - val_mae: 0.9850\nEpoch 2/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 1.6274 - mae: 0.9974 - val_loss: 1.5337 - val_mae: 0.9753\nEpoch 3/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 1.5121 - mae: 0.9331 - val_loss: 1.5277 - val_mae: 0.9644\nEpoch 4/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 1.4942 - mae: 0.9247 - val_loss: 1.5412 - val_mae: 0.9548\nEpoch 5/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 1.0849 - mae: 0.7670 - val_loss: 1.4926 - val_mae: 0.9536\nEpoch 6/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - loss: 0.7552 - mae: 0.6087 - val_loss: 1.4827 - val_mae: 0.9502\nEpoch 7/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 0.3943 - mae: 0.4222 - val_loss: 1.4914 - val_mae: 0.9492\nEpoch 8/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 0.1610 - mae: 0.2573 - val_loss: 1.5040 - val_mae: 0.9537\nEpoch 9/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 0.0942 - mae: 0.1888 - val_loss: 1.5090 - val_mae: 0.9532\nEpoch 10/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - loss: 0.0406 - mae: 0.1094 - val_loss: 1.5179 - val_mae: 0.9541\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fd7549c0b80>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"from tensorflow.keras.layers import GRU\n\ndef create_gru_model(input_shape):\n    model = Sequential()\n    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=input_shape))\n    model.add(GRU(128))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\ngru_model = create_gru_model(X_train.shape[1])\ngru_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:23:04.329837Z","iopub.execute_input":"2024-12-03T21:23:04.330567Z","iopub.status.idle":"2024-12-03T21:23:26.210867Z","shell.execute_reply.started":"2024-12-03T21:23:04.330524Z","shell.execute_reply":"2024-12-03T21:23:26.209992Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 14.6202 - mae: 3.4601 - val_loss: 1.9109 - val_mae: 1.1068\nEpoch 2/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 2.1084 - mae: 1.1693 - val_loss: 1.5095 - val_mae: 0.9565\nEpoch 3/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.9732 - mae: 0.7506 - val_loss: 1.3575 - val_mae: 0.8988\nEpoch 4/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.4838 - mae: 0.5014 - val_loss: 1.4735 - val_mae: 0.9350\nEpoch 5/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.1982 - mae: 0.3084 - val_loss: 1.5045 - val_mae: 0.9485\nEpoch 6/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.1104 - mae: 0.2227 - val_loss: 1.5484 - val_mae: 0.9660\nEpoch 7/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0681 - mae: 0.1690 - val_loss: 1.5683 - val_mae: 0.9714\nEpoch 8/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0673 - mae: 0.1481 - val_loss: 1.5944 - val_mae: 0.9811\nEpoch 9/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0607 - mae: 0.1499 - val_loss: 1.6281 - val_mae: 0.9885\nEpoch 10/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0471 - mae: 0.1407 - val_loss: 1.6388 - val_mae: 0.9857\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fd74c596b90>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"from tensorflow.keras.layers import LSTM\n\ndef create_lstm_model(input_shape):\n    model = Sequential()\n    model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=input_shape))\n    model.add(LSTM(128))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model\n\nlstm_model = create_lstm_model(X_train.shape[1])\nlstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:24:13.605225Z","iopub.execute_input":"2024-12-03T21:24:13.605601Z","iopub.status.idle":"2024-12-03T21:24:35.869140Z","shell.execute_reply.started":"2024-12-03T21:24:13.605562Z","shell.execute_reply":"2024-12-03T21:24:35.868000Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 12.7634 - mae: 3.0881 - val_loss: 1.5491 - val_mae: 0.9848\nEpoch 2/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 1.8028 - mae: 1.0610 - val_loss: 1.5356 - val_mae: 0.9661\nEpoch 3/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 1.5516 - mae: 0.9373 - val_loss: 1.4771 - val_mae: 0.9540\nEpoch 4/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 1.2660 - mae: 0.8556 - val_loss: 1.4245 - val_mae: 0.9505\nEpoch 5/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.6739 - mae: 0.6027 - val_loss: 1.4951 - val_mae: 0.9812\nEpoch 6/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.2455 - mae: 0.3630 - val_loss: 1.4872 - val_mae: 0.9682\nEpoch 7/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.1205 - mae: 0.2373 - val_loss: 1.5572 - val_mae: 0.9979\nEpoch 8/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0517 - mae: 0.1492 - val_loss: 1.5566 - val_mae: 0.9858\nEpoch 9/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0408 - mae: 0.1437 - val_loss: 1.5928 - val_mae: 1.0044\nEpoch 10/10\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0310 - mae: 0.1245 - val_loss: 1.5648 - val_mae: 0.9906\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fd74c230550>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"# Define the function to evaluate language models\ndef evaluate_language_models(models, X_test, y_test):\n    evaluation_results = {}\n    \n    for model_name, model in models.items():\n        # Evaluate the model using standard metrics\n        loss, mae = model.evaluate(X_test, y_test)\n        evaluation_results[model_name] = {'Loss': loss, 'MAE': mae}\n    \n    return evaluation_results\n\n# Define your models and their names\nmodels = {'Simple RNN': rnn_model, 'Bidirectional RNN': bidirectional_rnn_model, 'GRU': gru_model, 'LSTM': lstm_model}\n\n# Evaluate the language models\nevaluation_results = evaluate_language_models(models, X_test, y_test)\n\n# Print the evaluation results\nfor model_name, metrics in evaluation_results.items():\n    print(f\"{model_name} - Loss: {metrics['Loss']}, MAE: {metrics['MAE']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T21:25:30.746467Z","iopub.execute_input":"2024-12-03T21:25:30.746835Z","iopub.status.idle":"2024-12-03T21:25:32.111201Z","shell.execute_reply.started":"2024-12-03T21:25:30.746806Z","shell.execute_reply":"2024-12-03T21:25:32.110345Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5568 - mae: 0.9706\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.4344 - mae: 0.9325\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5156 - mae: 0.9499\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.4038 - mae: 0.9352\nSimple RNN - Loss: 1.6529250144958496, MAE: 0.9963415265083313\nBidirectional RNN - Loss: 1.517898440361023, MAE: 0.9540959596633911\nGRU - Loss: 1.638801097869873, MAE: 0.9857399463653564\nLSTM - Loss: 1.5648398399353027, MAE: 0.9905991554260254\n","output_type":"stream"}],"execution_count":57}]}